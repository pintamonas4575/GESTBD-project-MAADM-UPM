{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA 2: **DATOS NO ESTRUCTURADOS**\n",
    "\n",
    "**GRUPO:** GESTDB_2\n",
    "\n",
    "**MIEMBROS:** \n",
    "- JAIME ALVAREZ URUEÑA\n",
    "- ÁLVARO FRAILE CARMENA \n",
    "- ALEJANDRO MENDOZA MEDINA\n",
    "- JAVIER QUESADA PAJARES\n",
    "  \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4.element import ResultSet, Tag\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FUNCIONES AUXILIARES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_driver_name(string: str):\n",
    "    driver_dictionary={\n",
    "        'alb': 'Alex Albon',\n",
    "        'alo': 'Fernando Alonso',\n",
    "        'bea': 'Oliver Bearman',\n",
    "        'ber': 'Oliver Bearman', # repe\n",
    "        'bot': 'Valtteri Bottas',\n",
    "        'cha': 'Charles Leclerc', # repe\n",
    "        'col': 'Franco Colapinto',\n",
    "        'dev': 'Nyck Devries',\n",
    "        'gas': 'Pierre Gasly',\n",
    "        'gio': 'Antonio Giovinazzi',\n",
    "        'ham': 'Lewis Hamilton',\n",
    "        'hul': 'Nico Hulkenberg',\n",
    "        'kub': 'Robert Kubica',\n",
    "        'kvy': 'Daniil Kvyat',\n",
    "        'lat': 'Nicholas Latiffi',\n",
    "        'law': 'Liam Lawson',\n",
    "        'lec': 'Charles Leclerc',\n",
    "        'mag': 'Kevin Magnussen',\n",
    "        'max': 'Max Verstappen', # repe\n",
    "        'maz': 'Nikita Mazepin',\n",
    "        'msc': 'Mick Schumacher', # repe\n",
    "        'ndv': 'Nick de Vries', # nuevo\n",
    "        'nor': 'Lando Norris',\n",
    "        'oco': 'Esteban Ocon',\n",
    "        'per': 'Sergio Perez',\n",
    "        'pia': 'Oscar Piastri',\n",
    "        'rai': 'Kimi Raikkonen',\n",
    "        'ric': 'Daniel Ricciardo',\n",
    "        'rus': 'George Russell',\n",
    "        'sai': 'Carlos Sainz',\n",
    "        'sar': 'Logan Sargeant',\n",
    "        'sch': 'Mick Schumacher',\n",
    "        'str': 'Lance Stroll',\n",
    "        'tsu': 'Yuki Tsunoda',\n",
    "        'ver': 'Max Verstappen',\n",
    "        'vet': 'Sebastian Vettel',\n",
    "        'zho': 'Guanyu Zhou',\n",
    "    }\n",
    "    \n",
    "    lowers=string.lower()\n",
    "    for key,value in driver_dictionary.items():\n",
    "        if key in lowers:\n",
    "            return value\n",
    "    return 'Unknown driver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drivers_review(article_soup: BeautifulSoup):\n",
    "    drivers_reviews = []\n",
    "    pattern = re.compile(r'^prose max-w-none mb-l tablet')\n",
    "    text_items = article_soup.find_all('div', attrs={'class':pattern})[1:] # los primeros no valen, son la intro\n",
    "\n",
    "    for index, text_box in enumerate(text_items): \n",
    "        if index == 10: # después de la décima, chao\n",
    "            break\n",
    "\n",
    "        texto_completo = \"\"\n",
    "        for descendiente in text_box.contents:\n",
    "            if isinstance(descendiente, Tag): # los '\\n' de la lista ocultan los siguientes párrafos\n",
    "                if descendiente.name == 'h3' or descendiente.find('strong'): # \"missing out\" o \"read more\" \n",
    "                    break\n",
    "                else:\n",
    "                    texto_completo += descendiente.text+\" \"\n",
    "                \n",
    "        drivers_reviews.append(texto_completo)\n",
    "        \n",
    "    return drivers_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drivers_names_and_positions(article_soup: BeautifulSoup):\n",
    "    drivers_names = []\n",
    "    pattern = re.compile(r'^border-t-0')\n",
    "    driver_images = article_soup.find_all('div', attrs={'class':pattern})[:-1] # todas menos la última, la general\n",
    "\n",
    "    for index, imagen in enumerate(driver_images):\n",
    "        if index == 10: # a la décima paro\n",
    "            break\n",
    "        etiqueta_imagen = imagen.find('img')\n",
    "        nombre_imagen: str = etiqueta_imagen['alt']\n",
    "        drivers_names.append(decode_driver_name(nombre_imagen))\n",
    "\n",
    "    return drivers_names, [i for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking_date(article_soup: BeautifulSoup): \n",
    "    date_item = article_soup.find('time')\n",
    "\n",
    "    date_object = datetime.strptime(date_item.string, \"%d %B %Y\")\n",
    "    date_format = date_object.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking_page_data(url: str):\n",
    "    response = requests.get(url)\n",
    "    page_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    pattern = re.compile(r'^group group-hover:') # patrón de etiqueta de los artículos\n",
    "    articles_list = page_soup.find_all('a', attrs={'class':pattern})\n",
    "\n",
    "    dates_megalist = []\n",
    "    names_megalist = []\n",
    "    positions_megalist = []\n",
    "    reviews_megalist = []\n",
    "    links_megalist = []\n",
    "\n",
    "    for articulo in articles_list:\n",
    "        ranking_link_output = articulo['href'] # adicional, el link del ranking\n",
    "        \n",
    "        if 'fan' in ranking_link_output or 'pre-season' in ranking_link_output: # artículos inválidos\n",
    "            continue # saltar iteración\n",
    "        links_megalist.append(ranking_link_output)\n",
    "\n",
    "        response = requests.get(ranking_link_output) # mismo HTML para los 3 scrapers\n",
    "        article_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        date_output = get_ranking_date(article_soup) # PRIMERO, sacar fecha\n",
    "        dates_megalist.append(date_output)\n",
    "        \n",
    "        drivers_names_output, positions_output = get_drivers_names_and_positions(article_soup) # SEGUNDO, sacar nombres de los pilotos\n",
    "        names_megalist.append(drivers_names_output)\n",
    "        positions_megalist.append(positions_output)\n",
    "        \n",
    "        reviews_output = get_drivers_review(article_soup) # TERCERO, sacar el texto\n",
    "        reviews_megalist.append(reviews_output)\n",
    "\n",
    "    return dates_megalist, names_megalist, positions_megalist, reviews_megalist, links_megalist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Insertar una página entera de rankings en CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv('data/unstructured/rankings_info_pos.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.formula1.com/en/latest/tags/power-rankings.699Peq5SC9zNGvwCkb1ln6?page=5\"\n",
    "dates, drivers_names, positions, reviews, ranking_links = get_ranking_page_data(URL)\n",
    "\n",
    "for fecha, tanda_pilotos, posiciones, tanda_reviews, link in zip(dates, drivers_names, positions, reviews, ranking_links):\n",
    "    for piloto, posicion, review in zip(tanda_pilotos, posiciones, tanda_reviews):\n",
    "        new_row = [fecha, piloto, posicion, review, link]   \n",
    "        df.loc[len(df)] = new_row\n",
    "df.to_csv('data/unstructured/rankings_info_pos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar\n",
    "df = pd.DataFrame(columns=df.columns)\n",
    "df.to_csv('data/unstructured/rankings_info_pos.csv', index=False)\n",
    "df = pd.DataFrame(pd.read_csv('data/unstructured/rankings_info_pos.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Insertar varias páginas enteras de rankings en CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv('data/unstructured/rankings_info_pos.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Página [1] hecha\n",
      "Página [2] hecha\n",
      "Página [3] hecha\n",
      "Página [4] hecha\n",
      "Página [5] hecha\n",
      "Página [6] hecha\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.formula1.com/en/latest/tags/power-rankings.699Peq5SC9zNGvwCkb1ln6?page=\"\n",
    "\n",
    "for num_pagina in range(1,7):\n",
    "    url_pagina = URL + str(num_pagina)\n",
    "    dates, drivers_names, positions, reviews, ranking_links = get_ranking_page_data(url_pagina)\n",
    "\n",
    "    for fecha, tanda_pilotos, posiciones, tanda_reviews, link in zip(dates, drivers_names, positions, reviews, ranking_links):\n",
    "        for piloto, posicion, review in zip(tanda_pilotos, posiciones, tanda_reviews):\n",
    "            new_row = [fecha, piloto, posicion, review, link]   \n",
    "            df.loc[len(df)] = new_row\n",
    "    print(f'Página [{num_pagina}] hecha')\n",
    "df.to_csv('data/unstructured/rankings_info_pos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar\n",
    "df = pd.DataFrame(columns=df.columns)\n",
    "df.to_csv('data/unstructured/rankings_info_pos.csv', index=False)\n",
    "df = pd.DataFrame(pd.read_csv('data/unstructured/rankings_info_pos.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
